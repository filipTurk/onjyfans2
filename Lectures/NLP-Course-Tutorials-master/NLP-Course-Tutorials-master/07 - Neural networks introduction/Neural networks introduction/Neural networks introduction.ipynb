{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to (deep) neural networks\n",
    "\n",
    "<sup>This notebook is a part of Natural Language Processing class at the University of Ljubljana, Faculty for computer and information science. Please contact [slavko.zitnik@fri.uni-lj.si](mailto:slavko.zitnik@fri.uni-lj.si) for any comments.</sub>\n",
    "\n",
    "An artificial neural network is a network inspired by biological neural networks which are used to estimate or approximate functions that can depend on a large number of inputs. The notion *deep* comes from computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction.\n",
    "\n",
    "In this notebook we will use [Keras](https://keras.io/), which is a high-level API to train neural networks using different backends like [Tensorflow](https://github.com/tensorflow/tensorflow), [PyTorch](https://pytorch.org), [Theano](https://github.com/Theano/Theano) (old) or [CNTK](https://github.com/Microsoft/cntk) (old). \n",
    "\n",
    "For starters, we can check a simple Tensorflow's neural network visualization: [http://playground.tensorflow.org/](http://playground.tensorflow.org/).\n",
    "\n",
    "To install the basic requirements to work with Keras and Tensorflow, issue the following commands (for GPU-based installation, please see the [Tensorflow's documentation](https://www.tensorflow.org/install/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to neural networks\n",
    "\n",
    "A neural network (NN) is built from nodes (neurons) stacked in layers between the feature vector and the target vector. The simplest version of NN consists of one node - *perceptron*.\n",
    "\n",
    "The Perceptron is an algorithm for supervised learning of binary classifiers - functions that can decide whether an input (represented by a vector of numbers) belongs to one class or another. Much like logistic regression, the weights in a neural net are being multiplied by the input vertor summed up and feeded into the activation function's input.\n",
    "\n",
    "A Perceptron Network can be designed to have multiple layers, leading to the Multi-Layer Perceptron (MLP).\n",
    "\n",
    "<img src=\"imgs/single_layer.png\" width=\"65%\" />\n",
    "\n",
    "_(Source: Python Machine Learning, S. Raschka)_\n",
    "\n",
    "### Weights updating\n",
    "\n",
    "To find *the best* weights coefficients, we use an optimization algorithm (e.g. gradient descent). In every epoch we update the weight vector $w$ using the following update rule:\n",
    "\n",
    "$$\n",
    "w = w + \\Delta w, \\text{where } \\Delta w = - \\eta \\nabla J(w)\n",
    "$$\n",
    "\n",
    "To update the weights of the model, we update weights into the opposite direction (i.e. backward) of the gradient $ \\nabla J(w)$. \n",
    "\n",
    "In order to find the optimal weights of the model, we optimize an objective function (e.g. the sum of squared srrors) cost function $J(w)$. \n",
    "\n",
    "Furthermore, we multiply the gradient by a factor - the learning rate $\\eta$ , which we choose to balance the speed of learning against the risk of missing the global minimum of the cost function.\n",
    "\n",
    "### Activation function\n",
    "\n",
    "We define the activation function $\\phi(\\cdot)$ as follows:\n",
    "\n",
    "$$\n",
    "z = \\sum_{j} (w_j x_j + b_j) = \\mathbf{w}^T \\mathbf{x} + b\n",
    "$$\n",
    "\n",
    "$$\n",
    "a = \\phi(z)\n",
    "$$\n",
    "\n",
    "Examples of activation functions are $sigmoid$, $tanh$, $ReLu$, ...\n",
    "\n",
    "### Binary classification\n",
    "\n",
    "While we use the activation $\\phi(z)$ to compute the gradient update, we may use a threshold function _(Heaviside function)_ to squash the continuous-valued output into binary class labels for prediction:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \n",
    "\\begin{cases}\n",
    "    1 & \\text{if } \\phi(z) \\geq 0 \\\\\n",
    "    0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "## Multi-layer neural networks architecture \n",
    "\n",
    "<img src=\"imgs/multi-layers-1.png\" width=\"50%\" />\n",
    "\n",
    "_(Source: Python Machine Learning, S. Raschka)_\n",
    "\n",
    "The figure shows the concept of an MLP consisting of three layers: one _input_ layer, one _hidden_ layer, and one _output_ layer. \n",
    "\n",
    "The units in the hidden layer are fully connected to the input layer, and the output layer is fully connected to the hidden layer, respectively. \n",
    "\n",
    "If such a network has **more than one hidden layer**, we also call it a **deep artificial neural network**.\n",
    "\n",
    "\n",
    "\n",
    "Further we use Keras with a selected backend, which already has implemented all the needed statistical methods we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Keras\n",
    "\n",
    "\n",
    "### The Otto Group dataset (Kaggle) preparation\n",
    "\n",
    ">The Otto Group is one of the world’s biggest e-commerce companies, A consistent analysis of the performance of products is crucial. However, due to diverse global infrastructure, many identical products get classified differently.\n",
    "For this competition, we have provided a dataset with 93 features for more than 200,000 products. The objective is to build a predictive model which is able to distinguish between our main product categories. \n",
    "Each row corresponds to a single product. There are a total of 93 numerical features, which represent counts of different events. All features have been obfuscated and will not be defined any further.\n",
    "\n",
    "https://www.kaggle.com/c/otto-group-product-classification-challenge/data (downloaded data in folder *data/kaggle_ottogroup/* folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 9 classes and 93 features.\n",
      "Label values: ['Class_1' 'Class_2' 'Class_3' 'Class_4' 'Class_5' 'Class_6' 'Class_7'\n",
      " 'Class_8' 'Class_9']\n",
      "\n",
      "First three labels: ['Class_6' 'Class_6' 'Class_6']\n",
      "Labels are one-hot encoded for training: \n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Training data: \n",
      "[[-0.2535081  -0.21010602 -0.30716544 ... -0.1295155  -0.3869381\n",
      "  -0.10496315]\n",
      " [-0.2535081  -0.21010602 -0.30716544 ... -0.1295155  -0.3869381\n",
      "  -0.10496315]\n",
      " [-0.2535081  -0.21010602  2.0780103  ... -0.1295155  -0.3869381\n",
      "  -0.10496315]\n",
      " ...\n",
      " [-0.2535081  -0.21010602 -0.30716544 ... -0.1295155  -0.3869381\n",
      "  -0.10496315]\n",
      " [-0.2535081  -0.21010602 -0.30716544 ... -0.1295155   0.6310014\n",
      "  -0.10496315]\n",
      " [-0.2535081  -0.21010602 -0.30716544 ... -0.1295155  -0.3869381\n",
      "  -0.10496315]]\n"
     ]
    }
   ],
   "source": [
    "from scripts.kaggle_data import load_data, preprocess_data, preprocess_labels\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train, labels = load_data('data/kaggle_ottogroup/train.csv', train=True)\n",
    "X_train, scaler = preprocess_data(X_train)\n",
    "Y_train, encoder = preprocess_labels(labels)\n",
    "\n",
    "X_test, ids = load_data('data/kaggle_ottogroup/test.csv', train=False)\n",
    "X_test, _ = preprocess_data(X_test, scaler)\n",
    "\n",
    "nb_classes = Y_train.shape[1]\n",
    "dims = X_train.shape[1]\n",
    "\n",
    "print(f\"The dataset contains {nb_classes} classes and {dims} features.\")\n",
    "print(f\"Label values: {np.unique(labels)}\")\n",
    "print(f\"\\nFirst three labels: {labels[:3]}\")\n",
    "print(f\"Labels are one-hot encoded for training: \\n{Y_train}\")\n",
    "\n",
    "print(f\"\\nTraining data: \\n{X_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model ...\n",
      "Compile structure ...\n",
      "Fit model ...\n",
      "\u001b[1m1934/1934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275us/step - loss: 1.4023  \n",
      "\n",
      "Model description:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">846</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │           \u001b[38;5;34m846\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">848</span> (3.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m848\u001b[0m (3.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">846</span> (3.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m846\u001b[0m (3.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "print(\"Building model ...\")\n",
    "model = Sequential()\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(\"Compile structure ...\")\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "\n",
    "print(\"Fit model ...\")\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "print(\"\\nModel description:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras model visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to save image to file:\n",
    "#from keras.utils import plot_model\n",
    "#plot_model(model, to_file='model.png')\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils import model_to_dot\n",
    "import keras\n",
    "\n",
    "#Graphical (can also output to file - check documentation)\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dense layer** (for other predefined layers, see [Keras layers](https://keras.io/layers/about-keras-layers/)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "Dense(units, activation=None, use_bias=True, \n",
    "      kernel_initializer='glorot_uniform', bias_initializer='zeros', \n",
    "      kernel_regularizer=None, bias_regularizer=None, \n",
    "      activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "```\n",
    "\n",
    "* `units`: int > 0.\n",
    "\n",
    "* `activation`: name of activation function to use (see [activations](https://keras.io/activations/)), or alternatively, elementwise Theano function. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "\n",
    "* `use_bias`: whether to include a bias (i.e. make the layer affine rather than linear).\n",
    "\n",
    "* `kernel_initializer`: initializer for the kernel weights matrix (see [initializers](https://keras.io/initializers/)).\n",
    "\n",
    "* `bias_initializer`: initializer for the bias vector (see [initializers](https://keras.io/initializers/)).\n",
    "\n",
    "* `kernel_regularizer`: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "\n",
    "* `bias_regularizer`: instance of WeightRegularizer, applied to the bias.\n",
    "\n",
    "* `activity_regularizer`: instance of ActivityRegularizer, applied to the network output.\n",
    "\n",
    "* `kernel_constraint`: instance of the constraints module (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "\n",
    "* `bias_constraint`: instance of the constraints module, applied to the bias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfitting\n",
    "\n",
    "As neural networks feature many parameters, they are prone to overfitting. There are many approaches to avoid it, some of them are:\n",
    "\n",
    "* [Keras callbacks](https://keras.io/callbacks/) (EarlyStopping and ModelCheckpoint)\n",
    "* [Dropout layer](https://keras.io/api/layers/regularization_layers/dropout/)\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 0.8099 - val_loss: 0.7820\n",
      "Epoch 2/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 0.7941 - val_loss: 0.7653\n",
      "Epoch 3/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 0.7646 - val_loss: 0.7529\n",
      "Epoch 4/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.7693 - val_loss: 0.7425\n",
      "Epoch 5/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 0.7488 - val_loss: 0.7336\n",
      "Epoch 6/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 0.7392 - val_loss: 0.7264\n",
      "Epoch 7/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - loss: 0.7323 - val_loss: 0.7199\n",
      "Epoch 8/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 0.7293 - val_loss: 0.7145\n",
      "Epoch 9/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - loss: 0.7280 - val_loss: 0.7096\n",
      "Epoch 10/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.7176 - val_loss: 0.7054\n",
      "Epoch 11/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.7133 - val_loss: 0.7018\n",
      "Epoch 12/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 0.7060 - val_loss: 0.6982\n",
      "Epoch 13/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - loss: 0.7049 - val_loss: 0.6951\n",
      "Epoch 14/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.7085 - val_loss: 0.6925\n",
      "Epoch 15/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 0.6990 - val_loss: 0.6895\n",
      "Epoch 16/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.6987 - val_loss: 0.6872\n",
      "Epoch 17/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - loss: 0.6946 - val_loss: 0.6850\n",
      "Epoch 18/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - loss: 0.6948 - val_loss: 0.6832\n",
      "Epoch 19/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.6917 - val_loss: 0.6812\n",
      "Epoch 20/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - loss: 0.6959 - val_loss: 0.6794\n",
      "Epoch 21/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 0.6819 - val_loss: 0.6775\n",
      "Epoch 22/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - loss: 0.6831 - val_loss: 0.6761\n",
      "Epoch 23/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - loss: 0.6888 - val_loss: 0.6747\n",
      "Epoch 24/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.6856 - val_loss: 0.6732\n",
      "Epoch 25/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.6770 - val_loss: 0.6721\n",
      "Epoch 26/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 0.6822 - val_loss: 0.6710\n",
      "Epoch 27/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.6866 - val_loss: 0.6697\n",
      "Epoch 28/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - loss: 0.6737 - val_loss: 0.6687\n",
      "Epoch 29/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 0.6749 - val_loss: 0.6675\n",
      "Epoch 30/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 0.6739 - val_loss: 0.6665\n",
      "Epoch 31/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.6799 - val_loss: 0.6657\n",
      "Epoch 32/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 0.6745 - val_loss: 0.6648\n",
      "Epoch 33/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - loss: 0.6681 - val_loss: 0.6637\n",
      "Epoch 34/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.6730 - val_loss: 0.6630\n",
      "Epoch 35/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 0.6749 - val_loss: 0.6623\n",
      "Epoch 36/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.6749 - val_loss: 0.6615\n",
      "Epoch 37/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 0.6680 - val_loss: 0.6607\n",
      "Epoch 38/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 0.6678 - val_loss: 0.6601\n",
      "Epoch 39/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.6725 - val_loss: 0.6594\n",
      "Epoch 40/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 0.6629 - val_loss: 0.6586\n",
      "Epoch 41/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 0.6732 - val_loss: 0.6580\n",
      "Epoch 42/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.6649 - val_loss: 0.6577\n",
      "Epoch 43/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 0.6654 - val_loss: 0.6570\n",
      "Epoch 44/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 0.6739 - val_loss: 0.6565\n",
      "Epoch 45/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 0.6498 - val_loss: 0.6558\n",
      "Epoch 46/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.6645 - val_loss: 0.6554\n",
      "Epoch 47/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - loss: 0.6626 - val_loss: 0.6552\n",
      "Epoch 48/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 0.6694 - val_loss: 0.6546\n",
      "Epoch 49/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 0.6533 - val_loss: 0.6539\n",
      "Epoch 50/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 0.6646 - val_loss: 0.6535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x343e252a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EarlyStopping and ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.15, random_state=42)\n",
    "\n",
    "fBestModel = 'best_model.keras' \n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1) \n",
    "best_model = ModelCheckpoint(fBestModel, verbose=0, save_best_only=True)\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=50, \n",
    "          batch_size=128, verbose=True, callbacks=[best_model, early_stop]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer deep dense networks with Keras\n",
    "\n",
    "Keras offers two API-s to model neural network structure - Sequential API and Functional API. Using a sequential API, modelling a deep MLP can be done in only a few lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - loss: 1.5379 - val_loss: 0.8622\n",
      "Epoch 2/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - loss: 0.8361 - val_loss: 0.7720\n",
      "Epoch 3/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 0.7772 - val_loss: 0.7334\n",
      "Epoch 4/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - loss: 0.7345 - val_loss: 0.7106\n",
      "Epoch 5/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 0.7164 - val_loss: 0.6942\n",
      "Epoch 6/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 0.7002 - val_loss: 0.6832\n",
      "Epoch 7/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 0.6951 - val_loss: 0.6757\n",
      "Epoch 8/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 0.6845 - val_loss: 0.6696\n",
      "Epoch 9/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 0.6746 - val_loss: 0.6638\n",
      "Epoch 10/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - loss: 0.6783 - val_loss: 0.6600\n",
      "Epoch 11/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 0.6642 - val_loss: 0.6571\n",
      "Epoch 12/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - loss: 0.6554 - val_loss: 0.6535\n",
      "Epoch 13/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 0.6576 - val_loss: 0.6520\n",
      "Epoch 14/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - loss: 0.6728 - val_loss: 0.6495\n",
      "Epoch 15/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 0.6631 - val_loss: 0.6468\n",
      "Epoch 16/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - loss: 0.6579 - val_loss: 0.6462\n",
      "Epoch 17/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 0.6498 - val_loss: 0.6448\n",
      "Epoch 18/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 0.6518 - val_loss: 0.6433\n",
      "Epoch 19/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 0.6482 - val_loss: 0.6423\n",
      "Epoch 20/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 0.6557 - val_loss: 0.6404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x34413d360>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=20, \n",
    "          batch_size=128, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Test example: \n",
      "\t[[-0.2535081  -0.21010602 -0.30716544 -0.27944276 -0.1618665  -0.11933088\n",
      "  -0.18804485 -0.29366383 -0.29103777  2.52563    -0.41181517 -0.24841812\n",
      "  -0.23873688  0.41202334  0.18528318 -0.1857286  -0.2478012  -0.4307139\n",
      "  -0.11900038 -0.3277401  -0.29310533 -0.50474644 -0.18202722  0.5089937\n",
      "   0.6281596   0.25544888  0.10559219 -0.28857473 -0.1450437  -0.09160521\n",
      "  -0.165688   -0.43188646  0.23163353 -0.28095117 -0.20834123  0.11385515\n",
      "  -0.34829164  0.260751   -0.14722317 -0.19791047 -0.27952313 -0.35591894\n",
      "  -0.26444665 -0.41663927 -0.09204473 -0.2731184  -0.17263882 -0.61500263\n",
      "  -0.25436136 -0.18848683 -0.10373055 -0.20433451 -0.22031906 -0.5038467\n",
      "  -0.32352898 -0.15774053 -0.28564557 -0.17520699 -0.15075752 -0.34008545\n",
      "  -0.2356121  -0.44532695 -0.17818491  0.5123979  -0.28379902 -0.4197967\n",
      "  -0.58252704 -0.2231081   0.04594234  0.0552249  -0.2746733   0.05858203\n",
      "  -0.10220148 -0.15430625 -0.2271255  -0.25631952 -0.13698885 -0.13188471\n",
      "  -0.23370849 -0.3108527  -0.17010848 -0.2247894  -0.20399979 -0.06144607\n",
      "  -0.2800985   3.681262    0.38494045  9.040672   -0.29971188 -0.17669907\n",
      "  -0.1295155  -0.3869381  -0.10496315]]\n",
      "Predicted vector: \n",
      "\t[[7.7924769e-06 2.2002470e-01 3.0269256e-01 4.6936968e-01 1.0841914e-06\n",
      "  4.0350919e-06 7.8998003e-03 1.9836752e-07 1.4846064e-07]]\n",
      "Predicted class index: \n",
      "\t3\n"
     ]
    }
   ],
   "source": [
    "firstTestExample = X_test[:1]\n",
    "prediction = model.predict(firstTestExample)\n",
    "predictedClass = np.argmax(prediction)\n",
    "\n",
    "print(f\"Test example: \\n\\t{firstTestExample}\")\n",
    "print(f\"Predicted vector: \\n\\t{prediction}\")\n",
    "print(f\"Predicted class index: \\n\\t{predictedClass}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on - create and test your own structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 1.6216 - val_loss: 0.8734\n",
      "Epoch 2/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - loss: 0.8484 - val_loss: 0.7712\n",
      "Epoch 3/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.7722 - val_loss: 0.7308\n",
      "Epoch 4/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 0.7384 - val_loss: 0.7088\n",
      "Epoch 5/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 0.7092 - val_loss: 0.6943\n",
      "Epoch 6/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - loss: 0.6987 - val_loss: 0.6831\n",
      "Epoch 7/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 0.6903 - val_loss: 0.6750\n",
      "Epoch 8/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - loss: 0.6831 - val_loss: 0.6689\n",
      "Epoch 9/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - loss: 0.6817 - val_loss: 0.6640\n",
      "Epoch 10/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 0.6789 - val_loss: 0.6608\n",
      "Epoch 11/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 0.6677 - val_loss: 0.6572\n",
      "Epoch 12/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 0.6664 - val_loss: 0.6547\n",
      "Epoch 13/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - loss: 0.6635 - val_loss: 0.6520\n",
      "Epoch 14/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - loss: 0.6605 - val_loss: 0.6494\n",
      "Epoch 15/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 0.6538 - val_loss: 0.6473\n",
      "Epoch 16/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - loss: 0.6539 - val_loss: 0.6460\n",
      "Epoch 17/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 0.6536 - val_loss: 0.6450\n",
      "Epoch 18/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 0.6485 - val_loss: 0.6434\n",
      "Epoch 19/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.6471 - val_loss: 0.6429\n",
      "Epoch 20/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 0.6555 - val_loss: 0.6430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x36e759b40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100))\n",
    "\n",
    "# TODO: update model HERE and observe differences!\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=20, \n",
    "          batch_size=128, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other neural networks architectures\n",
    "\n",
    "There exist some known neural networks architectures as shown in the Figure below:\n",
    "    \n",
    "<img src=\"imgs/dl_overview.png\" >\n",
    "\n",
    "Credits: Yam Peleg ([@Yampeleg](https://twitter.com/yampeleg)) \n",
    "   \n",
    "### Convolutional neural networks (CNNs)\n",
    "\n",
    "<img src=\"imgs/same_padding_no_strides.gif\" width=\"50%\">\n",
    "\n",
    "*Image from*: [http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html](http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html)\n",
    "\n",
    "The first layer in a CNN is always a convolutional layer. \n",
    "\n",
    "After each convolutional layer, it is convention to apply a nonlinear layer (or activation layer, e.g. ReLU) immediately afterward. The purpose of this layer is to introduce nonlinearity to a system that basically has just been computing linear operations during the conv layers (just element wise multiplications and summations). It has been found out that ReLU layers work far better because the network is able to train a lot faster (because of the computational efficiency) without making a significant difference to the accuracy.\n",
    "\n",
    "After some ReLU layers, it is customary to apply a pooling layer (i.e. downsampling layer). As it reduces the number of parameters it can also be used to control overfitting. In this category, there are also several layer options, with maxpooling being the most popular:\n",
    "\n",
    "<img src=\"imgs/MaxPool.png\" width=\"80%\" />\n",
    "\n",
    "The last layer, however, is an important one, namely the fully connected layer. A fully connected layer looks at what high level features most strongly correlate to a particular class and has particular weights so that when you compute the products between the weights and the previous layer, you get the correct probabilities for the different classes.\n",
    "\n",
    "<img src=\"imgs/ConvNet LeNet.png\" width=\"90%\" />\n",
    "\n",
    "Check more about convolutional layer in [Keras documentation](https://keras.io/layers/convolutional/) or check [IMDB classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_cnn.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent neural networks (RNNs) and Long short term memory neural networks (LSTMs)\n",
    "\n",
    "<img src=\"imgs/rnn.png\" width=\"60%\">\n",
    "\n",
    "A recurrent neural network (RNN) is a class of artificial neural network where connections between units form a directed cycle. This creates an internal state of the network which allows it to exhibit dynamic temporal behavior.\n",
    "\n",
    "An LSTM network is an artificial neural network that contains LSTM blocks instead of, or in addition to, regular network units. A LSTM block may be described as a \"smart\" network unit that can remember a value for an arbitrary length of time. Unlike traditional RNNs, an Long short-term memory network is well-suited to learn from experience to classify, process and predict time series when there are very long time lags of unknown size between important events.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"imgs/gru_wiki.png\" width=\"100%\"></td>\n",
    "        <td><img src=\"imgs/lstm.png\" width=\"100%\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<img src=\"imgs/gru.png\" width=\"60%\">\n",
    "\n",
    "#### IMDB sentiment classification task\n",
    "\n",
    "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets.\n",
    "\n",
    "IMDB provided a set of 25,000 highly polar movie reviews for training, and 25,000 for testing.\n",
    "\n",
    "**Data preparation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "First example:\n",
      "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])]\n",
      "Pad sequences ...\n",
      "X_train shape: (25000, 100)\n",
      "X_test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 100  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print(\"Loading data...\")\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('First example:')\n",
    "print(X_train[:1])\n",
    "\n",
    "print(\"Pad sequences ...\")\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hands-on** - play with layers to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Epoch 1/4\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.5036 - loss: 0.7417 - val_accuracy: 0.5381 - val_loss: 0.6864\n",
      "Epoch 2/4\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.5828 - loss: 0.6648 - val_accuracy: 0.7408 - val_loss: 0.5396\n",
      "Epoch 3/4\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.7695 - loss: 0.5083 - val_accuracy: 0.7468 - val_loss: 0.5260\n",
      "Epoch 4/4\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.7711 - loss: 0.4898 - val_accuracy: 0.6833 - val_loss: 0.5828\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6806 - loss: 0.5879\n",
      "Test accuracy: 0.6832799911499023\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "\n",
    "# TODO: try changing\n",
    "model.add(SimpleRNN(128))  \n",
    "#model.add(GRU(128))  \n",
    "#model.add(LSTM(128))  \n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(\"Train...\")\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=4, validation_data=(X_test, y_test))\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "\n",
    "\"Word embeddings\" are a family of natural language processing techniques aiming at mapping semantic meaning into a geometric space. This is done by associating a numeric vector to every word in a dictionary, such that the distance (e.g. L2 distance or more commonly cosine distance) between any two vectors would capture part of the semantic relationship between the two associated words. The geometric space formed by these vectors is called an embedding space.\n",
    "\n",
    "Embeddings convert words to vectors in a high dimensional space. Each dimension denotes an aspect like gender, type of object / word. By converting words to vectors we build relations between words. More similar the words in a dimension, more closer their scores are.\n",
    "\n",
    "Training algorithms:\n",
    "\n",
    "<img src=\"imgs/cbow_skipgram.png\" width=\"80%\" />\n",
    "\n",
    "Credits: Mikolov et al. (2013), [Exploiting Similarities among Languages for Machine Translation](https://arxiv.org/pdf/1309.4168v1.pdf)\n",
    "\n",
    "### Word2Vec example\n",
    "\n",
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts: 4842\n",
      "First post: \n",
      "\t['Well, everyone got up and going this morning.  It\\'s still raining, but that\\'s okay with me.  Sort of suits my mood.  I could easily have stayed home in bed with my book and the cats.  This has been a lot of rain though!  People have wet basements, there are lakes where there should be golf courses and fields, everything is green, green, green.  But, it is supposed to be 26 degrees by Friday, so we\\'ll be dealing with mosquitos next week.  I heard Winnipeg described as an \"Old Testament\" city on  urlLink CBC Radio One  last week and it sort of rings true.  Floods, infestations, etc., etc..']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "DATA_DIRECTORY = os.path.join(os.path.abspath(os.path.curdir), 'data', 'word_embeddings')\n",
    "male_posts = []\n",
    "female_post = []\n",
    "with open(os.path.join(DATA_DIRECTORY,\"male_blog_list.txt\"),\"rb\") as male_file:\n",
    "    male_posts= pickle.load(male_file)\n",
    "    \n",
    "with open(os.path.join(DATA_DIRECTORY,\"female_blog_list.txt\"),\"rb\") as female_file:\n",
    "    female_posts = pickle.load(female_file)\n",
    "filtered_male_posts = list(filter(lambda p: len(p) > 0, male_posts))\n",
    "filtered_female_posts = list(filter(lambda p: len(p) > 0, female_posts))\n",
    "posts = filtered_female_posts + filtered_male_posts\n",
    "\n",
    "print(\"Number of posts: {}\".format(len(posts)))\n",
    "print(\"First post: \\n\\t{}\".format(posts[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "model = Word2Vec(vector_size=200, min_count=1)\n",
    "model.build_vocab(map(lambda x: x.split(), posts), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0,\n",
       " 'I': 1,\n",
       " 'to': 2,\n",
       " 'and': 3,\n",
       " 'a': 4,\n",
       " 'of': 5,\n",
       " 'that': 6,\n",
       " 'in': 7,\n",
       " 'my': 8,\n",
       " 'is': 9,\n",
       " 'it': 10,\n",
       " 'for': 11,\n",
       " 'was': 12,\n",
       " 'you': 13,\n",
       " 'have': 14,\n",
       " 'with': 15,\n",
       " 'on': 16,\n",
       " 'be': 17,\n",
       " 'but': 18,\n",
       " 'me': 19,\n",
       " 'i': 20,\n",
       " 'this': 21,\n",
       " 'so': 22,\n",
       " 'not': 23,\n",
       " 'at': 24,\n",
       " 'all': 25,\n",
       " 'just': 26,\n",
       " 'as': 27,\n",
       " \"I'm\": 28,\n",
       " 'are': 29,\n",
       " 'like': 30,\n",
       " 'about': 31,\n",
       " 'we': 32,\n",
       " 'or': 33,\n",
       " 'The': 34,\n",
       " 'out': 35,\n",
       " 'up': 36,\n",
       " 'from': 37,\n",
       " 'what': 38,\n",
       " 'he': 39,\n",
       " 'had': 40,\n",
       " 'get': 41,\n",
       " 'one': 42,\n",
       " 'will': 43,\n",
       " 'do': 44,\n",
       " 'they': 45,\n",
       " 'know': 46,\n",
       " 'can': 47,\n",
       " 'if': 48,\n",
       " 'some': 49,\n",
       " '-': 50,\n",
       " 'really': 51,\n",
       " \"don't\": 52,\n",
       " 'an': 53,\n",
       " 'your': 54,\n",
       " 'by': 55,\n",
       " 'when': 56,\n",
       " 'am': 57,\n",
       " 'think': 58,\n",
       " 'her': 59,\n",
       " 'urlLink': 60,\n",
       " 'would': 61,\n",
       " 'more': 62,\n",
       " 'And': 63,\n",
       " 'been': 64,\n",
       " 'his': 65,\n",
       " 'has': 66,\n",
       " 'time': 67,\n",
       " 'go': 68,\n",
       " 'she': 69,\n",
       " 'going': 70,\n",
       " 'then': 71,\n",
       " 'It': 72,\n",
       " 'there': 73,\n",
       " 'people': 74,\n",
       " 'got': 75,\n",
       " 'because': 76,\n",
       " 'want': 77,\n",
       " 'how': 78,\n",
       " 'no': 79,\n",
       " 'were': 80,\n",
       " \"it's\": 81,\n",
       " 'who': 82,\n",
       " 'good': 83,\n",
       " 'back': 84,\n",
       " 'only': 85,\n",
       " 'But': 86,\n",
       " 'see': 87,\n",
       " 'into': 88,\n",
       " 'much': 89,\n",
       " 'even': 90,\n",
       " 'could': 91,\n",
       " 'it.': 92,\n",
       " 'them': 93,\n",
       " 'make': 94,\n",
       " 'over': 95,\n",
       " 'now': 96,\n",
       " 'other': 97,\n",
       " 'So': 98,\n",
       " \"I've\": 99,\n",
       " 'our': 100,\n",
       " 'their': 101,\n",
       " 'which': 102,\n",
       " 'You': 103,\n",
       " 'than': 104,\n",
       " 'feel': 105,\n",
       " 'very': 106,\n",
       " 'something': 107,\n",
       " 'still': 108,\n",
       " 'him': 109,\n",
       " 'never': 110,\n",
       " 'things': 111,\n",
       " 'love': 112,\n",
       " 'me.': 113,\n",
       " 'its': 114,\n",
       " 'went': 115,\n",
       " 'last': 116,\n",
       " 'little': 117,\n",
       " 'did': 118,\n",
       " 'need': 119,\n",
       " 'He': 120,\n",
       " 'new': 121,\n",
       " 'way': 122,\n",
       " 'after': 123,\n",
       " 'being': 124,\n",
       " 'around': 125,\n",
       " 'My': 126,\n",
       " \"It's\": 127,\n",
       " \"I'll\": 128,\n",
       " 'should': 129,\n",
       " 'This': 130,\n",
       " 'too': 131,\n",
       " 'first': 132,\n",
       " 'A': 133,\n",
       " 'say': 134,\n",
       " 'day': 135,\n",
       " 'any': 136,\n",
       " \"can't\": 137,\n",
       " 'off': 138,\n",
       " 'where': 139,\n",
       " 'down': 140,\n",
       " 'thing': 141,\n",
       " 'take': 142,\n",
       " 'right': 143,\n",
       " 'We': 144,\n",
       " 'life': 145,\n",
       " \"didn't\": 146,\n",
       " 'two': 147,\n",
       " 'those': 148,\n",
       " 'most': 149,\n",
       " 'made': 150,\n",
       " 'work': 151,\n",
       " 'through': 152,\n",
       " 'here': 153,\n",
       " 'also': 154,\n",
       " 'said': 155,\n",
       " 'If': 156,\n",
       " 'thought': 157,\n",
       " 'always': 158,\n",
       " 'come': 159,\n",
       " 'find': 160,\n",
       " 'these': 161,\n",
       " '.': 162,\n",
       " 'myself': 163,\n",
       " 'me,': 164,\n",
       " 'next': 165,\n",
       " 'long': 166,\n",
       " 'before': 167,\n",
       " 'ever': 168,\n",
       " 'us': 169,\n",
       " 'why': 170,\n",
       " 'well': 171,\n",
       " 'many': 172,\n",
       " 'might': 173,\n",
       " 'since': 174,\n",
       " 'few': 175,\n",
       " 'it,': 176,\n",
       " 'look': 177,\n",
       " \"that's\": 178,\n",
       " 'someone': 179,\n",
       " 'In': 180,\n",
       " 'better': 181,\n",
       " 'pretty': 182,\n",
       " 'getting': 183,\n",
       " 'doing': 184,\n",
       " 'She': 185,\n",
       " 'im': 186,\n",
       " 'put': 187,\n",
       " 'while': 188,\n",
       " 'They': 189,\n",
       " 'every': 190,\n",
       " 'lot': 191,\n",
       " 'another': 192,\n",
       " 'best': 193,\n",
       " 'tell': 194,\n",
       " 'give': 195,\n",
       " 'night': 196,\n",
       " 'sure': 197,\n",
       " 'actually': 198,\n",
       " 'home': 199,\n",
       " 'What': 200,\n",
       " 'away': 201,\n",
       " 'world': 202,\n",
       " 'probably': 203,\n",
       " 'same': 204,\n",
       " 'came': 205,\n",
       " 'such': 206,\n",
       " 'maybe': 207,\n",
       " 'nothing': 208,\n",
       " 'keep': 209,\n",
       " 'today': 210,\n",
       " 'let': 211,\n",
       " 'may': 212,\n",
       " 'trying': 213,\n",
       " 'anything': 214,\n",
       " 'great': 215,\n",
       " 'own': 216,\n",
       " 'That': 217,\n",
       " 'everything': 218,\n",
       " 'try': 219,\n",
       " 'friends': 220,\n",
       " 'guess': 221,\n",
       " 'school': 222,\n",
       " 'bad': 223,\n",
       " 'until': 224,\n",
       " 'now.': 225,\n",
       " 'whole': 226,\n",
       " '2': 227,\n",
       " 'enough': 228,\n",
       " 'told': 229,\n",
       " 'start': 230,\n",
       " \"doesn't\": 231,\n",
       " 'that.': 232,\n",
       " 'dont': 233,\n",
       " 'time.': 234,\n",
       " 'hope': 235,\n",
       " \"you're\": 236,\n",
       " 'Well,': 237,\n",
       " 'end': 238,\n",
       " 'help': 239,\n",
       " 'without': 240,\n",
       " 'talk': 241,\n",
       " 'person': 242,\n",
       " 'hard': 243,\n",
       " 'left': 244,\n",
       " 'having': 245,\n",
       " 'days': 246,\n",
       " 'done': 247,\n",
       " 'old': 248,\n",
       " 'believe': 249,\n",
       " 'use': 250,\n",
       " 'started': 251,\n",
       " 'found': 252,\n",
       " 'year': 253,\n",
       " 'place': 254,\n",
       " 'God': 255,\n",
       " 'As': 256,\n",
       " 'bit': 257,\n",
       " 'again': 258,\n",
       " 'There': 259,\n",
       " 'blog': 260,\n",
       " 'everyone': 261,\n",
       " 'Not': 262,\n",
       " 'least': 263,\n",
       " 'wanted': 264,\n",
       " 'Then': 265,\n",
       " 'each': 266,\n",
       " 'call': 267,\n",
       " 'does': 268,\n",
       " 'though': 269,\n",
       " 'looking': 270,\n",
       " 'When': 271,\n",
       " 'quite': 272,\n",
       " 'part': 273,\n",
       " 'gonna': 274,\n",
       " 'nice': 275,\n",
       " '..': 276,\n",
       " 'post': 277,\n",
       " 'years': 278,\n",
       " 'able': 279,\n",
       " 'read': 280,\n",
       " 'used': 281,\n",
       " 'Just': 282,\n",
       " 'kind': 283,\n",
       " 'makes': 284,\n",
       " 'mean': 285,\n",
       " 'How': 286,\n",
       " 'now,': 287,\n",
       " '--': 288,\n",
       " 'called': 289,\n",
       " 'decided': 290,\n",
       " 'again.': 291,\n",
       " 'Best': 292,\n",
       " 'friend': 293,\n",
       " 'big': 294,\n",
       " 'seems': 295,\n",
       " 'week': 296,\n",
       " \"wasn't\": 297,\n",
       " 'All': 298,\n",
       " \"I'd\": 299,\n",
       " 'took': 300,\n",
       " 'happy': 301,\n",
       " 'you.': 302,\n",
       " 'almost': 303,\n",
       " 'head': 304,\n",
       " 'must': 305,\n",
       " 'Now': 306,\n",
       " 'making': 307,\n",
       " 'mind': 308,\n",
       " 'For': 309,\n",
       " 'remember': 310,\n",
       " 'play': 311,\n",
       " 'talking': 312,\n",
       " 'thinking': 313,\n",
       " 'else': 314,\n",
       " 'house': 315,\n",
       " 'them.': 316,\n",
       " 'far': 317,\n",
       " 'once': 318,\n",
       " 'fun': 319,\n",
       " 'Oh': 320,\n",
       " 'hate': 321,\n",
       " 'felt': 322,\n",
       " 'both': 323,\n",
       " '...': 324,\n",
       " 'movie': 325,\n",
       " 'stuff': 326,\n",
       " 'One': 327,\n",
       " 'live': 328,\n",
       " 'finally': 329,\n",
       " 'working': 330,\n",
       " \"won't\": 331,\n",
       " 'Well': 332,\n",
       " 'write': 333,\n",
       " 'past': 334,\n",
       " 'already': 335,\n",
       " 'saw': 336,\n",
       " 'anyone': 337,\n",
       " 'day.': 338,\n",
       " 'wish': 339,\n",
       " 'leave': 340,\n",
       " 'couple': 341,\n",
       " 'three': 342,\n",
       " 'No': 343,\n",
       " 'feeling': 344,\n",
       " 'coming': 345,\n",
       " ',': 346,\n",
       " \"there's\": 347,\n",
       " 'guy': 348,\n",
       " \"isn't\": 349,\n",
       " 'To': 350,\n",
       " 'you,': 351,\n",
       " 'hours': 352,\n",
       " 'yet': 353,\n",
       " 'up.': 354,\n",
       " 'life.': 355,\n",
       " 'half': 356,\n",
       " 'Maybe': 357,\n",
       " 'real': 358,\n",
       " 'heart': 359,\n",
       " 'show': 360,\n",
       " 'different': 361,\n",
       " 'asked': 362,\n",
       " '3': 363,\n",
       " 'time,': 364,\n",
       " 'him.': 365,\n",
       " \"haven't\": 366,\n",
       " 'game': 367,\n",
       " 'stop': 368,\n",
       " \"i'm\": 369,\n",
       " 'well,': 370,\n",
       " 'out.': 371,\n",
       " 'Today': 372,\n",
       " 'After': 373,\n",
       " 'man': 374,\n",
       " 'So,': 375,\n",
       " 'Your': 376,\n",
       " 'watch': 377,\n",
       " 'that,': 378,\n",
       " 'times': 379,\n",
       " 'today.': 380,\n",
       " 'care': 381,\n",
       " 'Why': 382,\n",
       " 'well.': 383,\n",
       " 'fact': 384,\n",
       " 'knew': 385,\n",
       " 'there.': 386,\n",
       " 'I’m': 387,\n",
       " \"That's\": 388,\n",
       " 'eyes': 389,\n",
       " 'seen': 390,\n",
       " 'become': 391,\n",
       " 'name': 392,\n",
       " 'Its': 393,\n",
       " 'face': 394,\n",
       " 'seem': 395,\n",
       " \"he's\": 396,\n",
       " \"we're\": 397,\n",
       " 'Or': 398,\n",
       " 'rather': 399,\n",
       " 'taking': 400,\n",
       " 'good.': 401,\n",
       " 'tried': 402,\n",
       " 'set': 403,\n",
       " 'change': 404,\n",
       " 'turn': 405,\n",
       " 'job': 406,\n",
       " 'wonder': 407,\n",
       " 'reading': 408,\n",
       " 'THE': 409,\n",
       " 'second': 410,\n",
       " 'looked': 411,\n",
       " 'between': 412,\n",
       " 'cool': 413,\n",
       " 'At': 414,\n",
       " 'free': 415,\n",
       " 'point': 416,\n",
       " 'morning': 417,\n",
       " 'thats': 418,\n",
       " 'computer': 419,\n",
       " 'means': 420,\n",
       " 'run': 421,\n",
       " 'reason': 422,\n",
       " 'idea': 423,\n",
       " 'do.': 424,\n",
       " 'gets': 425,\n",
       " 'hear': 426,\n",
       " 'mom': 427,\n",
       " 'girl': 428,\n",
       " 'during': 429,\n",
       " 'behind': 430,\n",
       " 'know,': 431,\n",
       " 'less': 432,\n",
       " 'miss': 433,\n",
       " 'family': 434,\n",
       " 'lost': 435,\n",
       " 'gave': 436,\n",
       " 'saying': 437,\n",
       " 'understand': 438,\n",
       " 'comes': 439,\n",
       " 'completely': 440,\n",
       " 'too.': 441,\n",
       " 'wants': 442,\n",
       " 'playing': 443,\n",
       " 'small': 444,\n",
       " 'supposed': 445,\n",
       " 'gone': 446,\n",
       " '4': 447,\n",
       " 'ask': 448,\n",
       " 'money': 449,\n",
       " 'against': 450,\n",
       " 'tired': 451,\n",
       " 'again,': 452,\n",
       " 'room': 453,\n",
       " 'all.': 454,\n",
       " 'later': 455,\n",
       " 'full': 456,\n",
       " 'hell': 457,\n",
       " 'His': 458,\n",
       " 'New': 459,\n",
       " 'cause': 460,\n",
       " 'wait': 461,\n",
       " 'car': 462,\n",
       " 'stupid': 463,\n",
       " 'watching': 464,\n",
       " 'one.': 465,\n",
       " 'sleep': 466,\n",
       " 'under': 467,\n",
       " 'move': 468,\n",
       " 'turned': 469,\n",
       " 'here.': 470,\n",
       " 'says': 471,\n",
       " 'seeing': 472,\n",
       " 'On': 473,\n",
       " 'close': 474,\n",
       " 'rest': 475,\n",
       " 'stay': 476,\n",
       " 'side': 477,\n",
       " 'up,': 478,\n",
       " 'heard': 479,\n",
       " 'fun.': 480,\n",
       " 'there,': 481,\n",
       " 'happened': 482,\n",
       " 'running': 483,\n",
       " 'phone': 484,\n",
       " 'goes': 485,\n",
       " 'interesting': 486,\n",
       " 'problem': 487,\n",
       " 'along': 488,\n",
       " 'words': 489,\n",
       " '5': 490,\n",
       " \"couldn't\": 491,\n",
       " 'walk': 492,\n",
       " 'writing': 493,\n",
       " 'her.': 494,\n",
       " 'oh': 495,\n",
       " 'matter': 496,\n",
       " 'looks': 497,\n",
       " 'knows': 498,\n",
       " 'soon': 499,\n",
       " 'played': 500,\n",
       " 'kinda': 501,\n",
       " \"Don't\": 502,\n",
       " 'spent': 503,\n",
       " \"wouldn't\": 504,\n",
       " 'know.': 505,\n",
       " 'living': 506,\n",
       " 'sitting': 507,\n",
       " \"they're\": 508,\n",
       " 'weekend': 509,\n",
       " 'today,': 510,\n",
       " 'minutes': 511,\n",
       " 'day,': 512,\n",
       " 'sort': 513,\n",
       " 'buy': 514,\n",
       " 'spend': 515,\n",
       " 'on.': 516,\n",
       " 'Do': 517,\n",
       " 'night.': 518,\n",
       " 'wrong': 519,\n",
       " 'front': 520,\n",
       " '1': 521,\n",
       " 'guys': 522,\n",
       " 'Is': 523,\n",
       " 'hold': 524,\n",
       " 'kids': 525,\n",
       " 'all,': 526,\n",
       " 'waiting': 527,\n",
       " 'course': 528,\n",
       " 'story': 529,\n",
       " 'others': 530,\n",
       " 'eat': 531,\n",
       " 'together': 532,\n",
       " 'word': 533,\n",
       " 'is,': 534,\n",
       " 'site': 535,\n",
       " 'worth': 536,\n",
       " 'parents': 537,\n",
       " 'light': 538,\n",
       " 'hit': 539,\n",
       " '\"I': 540,\n",
       " 'tomorrow': 541,\n",
       " 'brought': 542,\n",
       " 'instead': 543,\n",
       " 'whatever': 544,\n",
       " 'moment': 545,\n",
       " 'open': 546,\n",
       " 'people.': 547,\n",
       " 'Im': 548,\n",
       " 'book': 549,\n",
       " 'back.': 550,\n",
       " 'u': 551,\n",
       " 'is.': 552,\n",
       " 'out,': 553,\n",
       " 'say,': 554,\n",
       " 'him,': 555,\n",
       " 'though,': 556,\n",
       " 'ready': 557,\n",
       " 'Who': 558,\n",
       " 'way.': 559,\n",
       " 'high': 560,\n",
       " 'months': 561,\n",
       " '(': 562,\n",
       " 'don’t': 563,\n",
       " 'sit': 564,\n",
       " 'funny': 565,\n",
       " 'bring': 566,\n",
       " 'life,': 567,\n",
       " 'American': 568,\n",
       " 'top': 569,\n",
       " 'starting': 570,\n",
       " 'this.': 571,\n",
       " 'though.': 572,\n",
       " 'important': 573,\n",
       " 'to.': 574,\n",
       " 'inside': 575,\n",
       " 'myself.': 576,\n",
       " 'hot': 577,\n",
       " '10': 578,\n",
       " 'fucking': 579,\n",
       " 'hour': 580,\n",
       " 'weeks': 581,\n",
       " 'simply': 582,\n",
       " 'summer': 583,\n",
       " 'Of': 584,\n",
       " 'way,': 585,\n",
       " 'using': 586,\n",
       " 'dad': 587,\n",
       " 'damn': 588,\n",
       " 'learn': 589,\n",
       " 'upon': 590,\n",
       " 'sometimes': 591,\n",
       " 'cannot': 592,\n",
       " 'this,': 593,\n",
       " 'order': 594,\n",
       " 'especially': 595,\n",
       " 'water': 596,\n",
       " 'true': 597,\n",
       " 'figure': 598,\n",
       " 'Oh,': 599,\n",
       " 'class': 600,\n",
       " 'bed': 601,\n",
       " 'music': 602,\n",
       " 'check': 603,\n",
       " 'yesterday': 604,\n",
       " '2.': 605,\n",
       " 'thing.': 606,\n",
       " \"she's\": 607,\n",
       " 'watched': 608,\n",
       " 'here,': 609,\n",
       " 'crazy': 610,\n",
       " 'year.': 611,\n",
       " 'didnt': 612,\n",
       " 'fall': 613,\n",
       " ':)': 614,\n",
       " 'exactly': 615,\n",
       " 'kept': 616,\n",
       " 'Even': 617,\n",
       " 'Last': 618,\n",
       " 'With': 619,\n",
       " 'within': 620,\n",
       " 'finished': 621,\n",
       " 'ended': 622,\n",
       " 'either': 623,\n",
       " 'taken': 624,\n",
       " 'film': 625,\n",
       " 'shit': 626,\n",
       " 'pay': 627,\n",
       " 'Anyways,': 628,\n",
       " 'thoughts': 629,\n",
       " 'them,': 630,\n",
       " 'outside': 631,\n",
       " 'song': 632,\n",
       " 'online': 633,\n",
       " 'totally': 634,\n",
       " 'given': 635,\n",
       " 'five': 636,\n",
       " 'be.': 637,\n",
       " 'needed': 638,\n",
       " 'hand': 639,\n",
       " 'realize': 640,\n",
       " 'However,': 641,\n",
       " 'deal': 642,\n",
       " 'certain': 643,\n",
       " 'Because': 644,\n",
       " 'break': 645,\n",
       " 'often': 646,\n",
       " 'dream': 647,\n",
       " 'late': 648,\n",
       " 'wanna': 649,\n",
       " 'number': 650,\n",
       " 'telling': 651,\n",
       " 'sense': 652,\n",
       " 'Anyway,': 653,\n",
       " 'truly': 654,\n",
       " 'night,': 655,\n",
       " 'hands': 656,\n",
       " 'away.': 657,\n",
       " 'short': 658,\n",
       " 'work.': 659,\n",
       " 'meet': 660,\n",
       " 'walked': 661,\n",
       " 'test': 662,\n",
       " 'onto': 663,\n",
       " 'known': 664,\n",
       " 'longer': 665,\n",
       " 'home.': 666,\n",
       " 'Okay,': 667,\n",
       " 'single': 668,\n",
       " 'cant': 669,\n",
       " 'Some': 670,\n",
       " 'met': 671,\n",
       " 'off.': 672,\n",
       " 'hair': 673,\n",
       " 'sound': 674,\n",
       " 'more.': 675,\n",
       " 'body': 676,\n",
       " 'till': 677,\n",
       " 'in.': 678,\n",
       " 'people,': 679,\n",
       " 'mad': 680,\n",
       " '6': 681,\n",
       " 'alone': 682,\n",
       " 'Which': 683,\n",
       " 'stuff.': 684,\n",
       " 'needs': 685,\n",
       " 'chance': 686,\n",
       " 'hurt': 687,\n",
       " 'shall': 688,\n",
       " ':': 689,\n",
       " 'talked': 690,\n",
       " 'happen': 691,\n",
       " 'ago': 692,\n",
       " 'realized': 693,\n",
       " 'Mr.': 694,\n",
       " 'sick': 695,\n",
       " 'things.': 696,\n",
       " 'But,': 697,\n",
       " 'Current': 698,\n",
       " 'blog.': 699,\n",
       " 'week.': 700,\n",
       " 'feels': 701,\n",
       " 'seemed': 702,\n",
       " '(I': 703,\n",
       " 'awesome': 704,\n",
       " 'course,': 705,\n",
       " 'across': 706,\n",
       " 'human': 707,\n",
       " 'something.': 708,\n",
       " 'ones': 709,\n",
       " \"you'll\": 710,\n",
       " 'yourself': 711,\n",
       " 'changed': 712,\n",
       " 'mean,': 713,\n",
       " 'early': 714,\n",
       " 'special': 715,\n",
       " 'sorry': 716,\n",
       " '(and': 717,\n",
       " 'her,': 718,\n",
       " 'not.': 719,\n",
       " 'on,': 720,\n",
       " 'walking': 721,\n",
       " 'us.': 722,\n",
       " 'drive': 723,\n",
       " 'forward': 724,\n",
       " 'huge': 725,\n",
       " 'Lord': 726,\n",
       " 'food': 727,\n",
       " 'learned': 728,\n",
       " 'go.': 729,\n",
       " 'power': 730,\n",
       " 'Like': 731,\n",
       " 'tonight': 732,\n",
       " 'pick': 733,\n",
       " 'usually': 734,\n",
       " 'brother': 735,\n",
       " 'question': 736,\n",
       " 'school.': 737,\n",
       " 'email': 738,\n",
       " \"He's\": 739,\n",
       " 'easy': 740,\n",
       " 'it?': 741,\n",
       " 'work,': 742,\n",
       " 'band': 743,\n",
       " 'except': 744,\n",
       " 'By': 745,\n",
       " 'lack': 746,\n",
       " 'John': 747,\n",
       " 'bought': 748,\n",
       " 'enjoy': 749,\n",
       " \"aren't\": 750,\n",
       " 'cool.': 751,\n",
       " 'lives': 752,\n",
       " 'whether': 753,\n",
       " 'girls': 754,\n",
       " 'written': 755,\n",
       " 'takes': 756,\n",
       " 'do,': 757,\n",
       " 'glad': 758,\n",
       " 'bad.': 759,\n",
       " 'dark': 760,\n",
       " 'four': 761,\n",
       " 'pain': 762,\n",
       " 'about.': 763,\n",
       " 'sister': 764,\n",
       " 'please': 765,\n",
       " 'stand': 766,\n",
       " '\"The': 767,\n",
       " 'problems': 768,\n",
       " 'dear': 769,\n",
       " \"There's\": 770,\n",
       " 'sun': 771,\n",
       " 'weird': 772,\n",
       " 'OF': 773,\n",
       " '\"': 774,\n",
       " 'team': 775,\n",
       " 'black': 776,\n",
       " 'personal': 777,\n",
       " 'myself,': 778,\n",
       " 'lots': 779,\n",
       " 'People': 780,\n",
       " 'middle': 781,\n",
       " 'beautiful': 782,\n",
       " 'gotten': 783,\n",
       " 'trip': 784,\n",
       " 'picture': 785,\n",
       " 'due': 786,\n",
       " 'page': 787,\n",
       " 'pictures': 788,\n",
       " '7': 789,\n",
       " 'line': 790,\n",
       " 'party': 791,\n",
       " 'dead': 792,\n",
       " 'giving': 793,\n",
       " 'gives': 794,\n",
       " 'Yes,': 795,\n",
       " 'baby': 796,\n",
       " 'door': 797,\n",
       " 'group': 798,\n",
       " 'strong': 799,\n",
       " 'although': 800,\n",
       " 'mention': 801,\n",
       " 'amazing': 802,\n",
       " 'world.': 803,\n",
       " 'finish': 804,\n",
       " 'fuck': 805,\n",
       " 'perfect': 806,\n",
       " 'sat': 807,\n",
       " 'favorite': 808,\n",
       " 'kill': 809,\n",
       " 'type': 810,\n",
       " 'much.': 811,\n",
       " 'including': 812,\n",
       " 'men': 813,\n",
       " 'friends.': 814,\n",
       " 'anymore.': 815,\n",
       " 'listening': 816,\n",
       " 'relationship': 817,\n",
       " 'Sometimes': 818,\n",
       " \"you've\": 819,\n",
       " 'entire': 820,\n",
       " 'Thank': 821,\n",
       " 'said,': 822,\n",
       " 'boring': 823,\n",
       " 'sad': 824,\n",
       " 'wake': 825,\n",
       " 'Good': 826,\n",
       " \"i'll\": 827,\n",
       " 'young': 828,\n",
       " 'forget': 829,\n",
       " 'managed': 830,\n",
       " 'good,': 831,\n",
       " 'experience': 832,\n",
       " 'asking': 833,\n",
       " 'so,': 834,\n",
       " 'nearly': 835,\n",
       " 'ws': 836,\n",
       " 'happens': 837,\n",
       " 'case': 838,\n",
       " 'leaving': 839,\n",
       " 'knowing': 840,\n",
       " 'place.': 841,\n",
       " 'down.': 842,\n",
       " 'afraid': 843,\n",
       " 'news': 844,\n",
       " 'Bush': 845,\n",
       " 'questions': 846,\n",
       " 'woman': 847,\n",
       " \"we'll\": 848,\n",
       " 'friends,': 849,\n",
       " 'loved': 850,\n",
       " 'school,': 851,\n",
       " 'games': 852,\n",
       " 'simple': 853,\n",
       " 'forgot': 854,\n",
       " 'hang': 855,\n",
       " 'future': 856,\n",
       " 'month': 857,\n",
       " 'mine': 858,\n",
       " 'sweet': 859,\n",
       " 'practice': 860,\n",
       " 'perhaps': 861,\n",
       " 'white': 862,\n",
       " 'ran': 863,\n",
       " 'yeah,': 864,\n",
       " 'one,': 865,\n",
       " 'Have': 866,\n",
       " 'lead': 867,\n",
       " 'me?': 868,\n",
       " 'Are': 869,\n",
       " 'worry': 870,\n",
       " 'say.': 871,\n",
       " 'plan': 872,\n",
       " \"i've\": 873,\n",
       " 'More': 874,\n",
       " 'cold': 875,\n",
       " 'great.': 876,\n",
       " '20': 877,\n",
       " 'company': 878,\n",
       " \"what's\": 879,\n",
       " 'stuck': 880,\n",
       " 'listen': 881,\n",
       " 'it’s': 882,\n",
       " 'driving': 883,\n",
       " 'won': 884,\n",
       " 'deep': 885,\n",
       " 'towards': 886,\n",
       " 'am,': 887,\n",
       " 'begin': 888,\n",
       " 'share': 889,\n",
       " 'major': 890,\n",
       " 'ass': 891,\n",
       " 'dreams': 892,\n",
       " 'then,': 893,\n",
       " 'woke': 894,\n",
       " 'ok': 895,\n",
       " 'boy': 896,\n",
       " 'Michael': 897,\n",
       " 'wonderful': 898,\n",
       " 'Here': 899,\n",
       " 'suppose': 900,\n",
       " 'AND': 901,\n",
       " 'stopped': 902,\n",
       " 'website': 903,\n",
       " 'wrote': 904,\n",
       " 'several': 905,\n",
       " 'large': 906,\n",
       " 'absolutely': 907,\n",
       " 'crap': 908,\n",
       " 'meant': 909,\n",
       " 'better.': 910,\n",
       " 'hopefully': 911,\n",
       " 'While': 912,\n",
       " 'hoping': 913,\n",
       " 'fear': 914,\n",
       " 'thing,': 915,\n",
       " 'link': 916,\n",
       " 'ya': 917,\n",
       " 'Our': 918,\n",
       " 'add': 919,\n",
       " 'war': 920,\n",
       " 'forever': 921,\n",
       " 'complete': 922,\n",
       " '1.': 923,\n",
       " 'mind.': 924,\n",
       " 'week,': 925,\n",
       " 'current': 926,\n",
       " 'back,': 927,\n",
       " 'Nothing': 928,\n",
       " 'control': 929,\n",
       " 'step': 930,\n",
       " 'held': 931,\n",
       " 'answer': 932,\n",
       " 'Now,': 933,\n",
       " 'with.': 934,\n",
       " \"You're\": 935,\n",
       " 'smile': 936,\n",
       " 'cry': 937,\n",
       " 'continue': 938,\n",
       " 'First': 939,\n",
       " 'expect': 940,\n",
       " 'ive': 941,\n",
       " 'home,': 942,\n",
       " 'turns': 943,\n",
       " 'yes,': 944,\n",
       " 'eating': 945,\n",
       " 'fine': 946,\n",
       " 'doubt': 947,\n",
       " 'lose': 948,\n",
       " 'works': 949,\n",
       " 'worked': 950,\n",
       " 'days.': 951,\n",
       " 'These': 952,\n",
       " 'year,': 953,\n",
       " 'starts': 954,\n",
       " 'web': 955,\n",
       " 'speak': 956,\n",
       " 'ill': 957,\n",
       " 'information': 958,\n",
       " 'TO': 959,\n",
       " 'fight': 960,\n",
       " 'done.': 961,\n",
       " 'thank': 962,\n",
       " 'morning.': 963,\n",
       " 'article': 964,\n",
       " 'lol': 965,\n",
       " 'arms': 966,\n",
       " 'kid': 967,\n",
       " 'Where': 968,\n",
       " 'die': 969,\n",
       " 'Go': 970,\n",
       " 'ride': 971,\n",
       " 'near': 972,\n",
       " 'Her': 973,\n",
       " 'weekend.': 974,\n",
       " 'King': 975,\n",
       " 'o': 976,\n",
       " 'trust': 977,\n",
       " 'update': 978,\n",
       " 'college': 979,\n",
       " 'act': 980,\n",
       " 'bored': 981,\n",
       " 'Sunday': 982,\n",
       " 'Friday': 983,\n",
       " 'definitely': 984,\n",
       " 'house.': 985,\n",
       " 'excited': 986,\n",
       " 'noticed': 987,\n",
       " 'liked': 988,\n",
       " '(which': 989,\n",
       " 'Written.': 990,\n",
       " 'fell': 991,\n",
       " 'alot': 992,\n",
       " \"She's\": 993,\n",
       " 'things,': 994,\n",
       " 'Let': 995,\n",
       " 'cut': 996,\n",
       " 'From': 997,\n",
       " 'pass': 998,\n",
       " 'random': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04193627"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('I', 'mine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.063584596"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('ring', 'wife')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.018875381"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('ring', 'husband')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.09124453"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('woman', 'housewife')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.17411754"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('man', 'housewife')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.3630428e-03, -3.3598423e-03, -3.5549831e-03,  2.4528505e-04,\n",
       "       -4.7614449e-03,  4.7613895e-03,  4.5550489e-03,  3.8771622e-03,\n",
       "       -3.6376668e-03,  1.4804178e-03, -2.5148613e-03,  1.9925713e-04,\n",
       "        3.5984910e-03,  3.9677023e-05, -3.0117340e-03,  4.5156684e-03,\n",
       "       -4.4915997e-03,  1.1738902e-03, -3.0967165e-03, -4.7881519e-03,\n",
       "        2.5495952e-03, -2.7948045e-03,  9.4641444e-05, -8.7865291e-04,\n",
       "       -8.1568956e-05, -3.4165145e-03,  2.0121546e-03,  4.0507037e-03,\n",
       "       -6.7526104e-05, -1.6083288e-03, -2.2245015e-03, -4.7872807e-03,\n",
       "        2.3600643e-03,  1.7021084e-03, -3.8681501e-03, -1.0601550e-03,\n",
       "       -2.9002053e-03,  2.0705992e-03, -3.2816262e-03,  1.8762333e-03,\n",
       "       -2.8380847e-03,  3.3261932e-03, -1.4033436e-03, -1.2078601e-03,\n",
       "        3.6673206e-03,  1.6874432e-03, -1.5490473e-04,  4.4890614e-03,\n",
       "        3.4259940e-03,  4.0852050e-03, -4.7534453e-03,  6.7709089e-04,\n",
       "       -1.5969985e-03, -2.5910216e-03,  2.5340961e-03,  6.0849666e-04,\n",
       "       -4.6317060e-03, -1.0041404e-03, -1.3085424e-03, -8.3510281e-04,\n",
       "        4.8431782e-03,  4.8770714e-03, -3.2308530e-03, -2.6959837e-03,\n",
       "        3.0843581e-03, -4.7037541e-04,  2.3203921e-03,  2.7410823e-03,\n",
       "        3.7456232e-03,  3.2821209e-03,  4.1624461e-03,  1.0556728e-03,\n",
       "        1.7412931e-03, -1.4119470e-03, -3.4594291e-03,  2.1316123e-03,\n",
       "        1.5169233e-03, -3.0024571e-03, -2.7986455e-03, -1.5437615e-03,\n",
       "       -2.0213502e-03, -2.3067326e-03, -3.7125903e-03,  1.6448325e-03,\n",
       "       -1.0309100e-04,  1.5436762e-03, -1.9314051e-04,  2.2313304e-03,\n",
       "        2.2290975e-03,  4.0241443e-03, -2.7560408e-03, -3.4522135e-03,\n",
       "       -1.8698204e-03, -3.9106067e-03,  2.1108771e-03,  4.7801613e-04,\n",
       "        3.9947508e-03,  2.2375905e-03,  3.4715189e-03, -1.8570685e-03,\n",
       "        2.1525330e-03, -4.6413601e-03,  3.5635538e-03, -8.1491412e-04,\n",
       "        3.1848210e-03, -4.4866544e-03, -4.4257734e-03, -9.1871974e-04,\n",
       "       -2.1583170e-03, -3.8134283e-03,  2.9145593e-03, -1.7594159e-04,\n",
       "       -2.7120591e-04, -2.0271463e-03, -3.2714808e-03, -1.6784859e-03,\n",
       "        4.4920028e-04, -8.0256345e-04, -4.2127925e-03, -3.8132649e-03,\n",
       "       -4.5938422e-03,  2.8314120e-03,  1.9136280e-03,  3.3145798e-03,\n",
       "       -2.8447139e-03,  4.7193561e-03, -4.0283948e-03, -2.8231908e-03,\n",
       "       -7.1418282e-05,  3.3689244e-03, -2.3147035e-03, -3.9049203e-03,\n",
       "       -4.8462409e-03,  1.2104845e-03, -3.1207139e-03, -4.4454038e-03,\n",
       "       -1.4774996e-03, -2.8629543e-04,  4.9059570e-04, -1.9822896e-03,\n",
       "       -5.1792862e-04,  2.6964844e-04,  1.7224163e-03, -9.6408126e-05,\n",
       "        1.0408956e-03,  8.1580936e-04, -2.2119887e-03, -1.6780519e-03,\n",
       "       -4.1729002e-03, -2.0363098e-03,  3.1131930e-03, -4.7559678e-03,\n",
       "       -1.0125935e-04,  1.9951684e-03,  3.7711305e-03,  4.1906987e-03,\n",
       "        1.9727349e-05,  3.1620442e-04, -2.4449169e-03,  1.3792295e-03,\n",
       "        4.2294590e-03,  4.3885428e-03,  4.6540219e-03,  4.5077638e-03,\n",
       "       -3.2931441e-03,  9.3757868e-04,  3.6625534e-03,  2.2687227e-03,\n",
       "       -4.4779666e-03, -6.9971976e-04,  3.6116624e-03,  4.4193538e-03,\n",
       "        1.7206348e-03,  5.3909601e-04,  2.1623135e-04, -8.9758873e-04,\n",
       "        3.9756242e-03, -8.9280726e-04,  1.6954184e-03,  1.0637116e-03,\n",
       "       -3.6168909e-03, -4.8874780e-03,  3.5791396e-05,  4.9446579e-03,\n",
       "       -3.9352542e-03, -3.1197369e-03,  4.6995138e-03,  4.9184979e-04,\n",
       "       -3.5938930e-03, -7.0602598e-04, -3.6543077e-03,  4.0261634e-03,\n",
       "        1.4320862e-03, -1.3382655e-03,  8.1460597e-04,  4.1341884e-03,\n",
       "        2.3588222e-03, -4.4575988e-04, -1.0543395e-03, -1.3834912e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019060344"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('computer', 'keyboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0985767"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('computer', 'mouse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04905799"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('mouse', 'elephant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'breakfast'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use these results in Keras, Embedding layer can be used or input data can be manually transformed into Word2Vec vectors prior to feeding the neural network.\n",
    "\n",
    "## Hands-on ideas\n",
    "\n",
    "* Change the parameters or text above and observe differences.\n",
    "* Check [http://szitnik.github.io/word2vec-tsne/offensive_v2.html](http://szitnik.github.io/word2vec-tsne/offensive_v2.html) to get some ideas of how to use word embeddings. Also, check this repository [https://github.com/UL-FRI-Zitnik/offensive-language-organization](https://github.com/UL-FRI-Zitnik/offensive-language-organization) for further examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further resources\n",
    "\n",
    "* Online book: [http://neuralnetworksanddeeplearning.com/](http://neuralnetworksanddeeplearning.com/)\n",
    "* GitHub repository of iPython notebooks tutorials on Keras & Tensorflow: [https://github.com/leriomaggio/deep-learning-keras-tensorflow](https://github.com/leriomaggio/deep-learning-keras-tensorflow) (parts of them also used in this notebook)\n",
    "* Google Codelabs tutorial: [https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0)\n",
    "* Tensorflow tutorial: [https://www.tensorflow.org/tutorials/](https://www.tensorflow.org/tutorials/)\n",
    "* Andrew Ng's Machine Learning Coursera course: [https://www.coursera.org/learn/machine-learning](https://www.coursera.org/learn/machine-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
