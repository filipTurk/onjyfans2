{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7b0317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'messages': [{'role': 'user', 'content': 'B1: Nesre?eCesta RoÅ¾na Dolina - AjÅ¡evica je pri AjÅ¡evici zaprta.Cesta Pesek - Oplotnica je v Oplotnici zaprta.OpozorilaNa avtocesti od SeÅ¾ane proti Mariboru, do Slovenskih Konjic, pelje izredni prevoz. Ob?asno je lahko promet oviran in upo?asnjen.Mejni prehodi?akalna doba je na mejnem prehodu ObreÅ¾je.Tovorni prometZaradi praznikov bo po Sloveniji v nedeljo, 1. 5. in v ponedeljek, 2. 5. med 8. in 22. uro, veljala omejitev prometa tovornih vozil, katerih najve?ja dovoljena masa presega 7,5 t.'}, {'role': 'assistant', 'content': 'Zaradi prometne nesreče je zaprta regionalna cesta Ajševica-Rožna Dolina, in to pri Ajševici. Na mejnem prehodu Obrežje vozniki na vstop v državo čakajo do dve uri, v Gruškovju pa pol ure.  \\nPovečan promet pri izstopu iz države pa je na prehodu Dobovec, na katerem vozniki čakajo uro in pol, ter na Obrežju in v Gruškovju, v katerem vozniki čakajo pol ure.\\n'}]}, {'messages': [{'role': 'user', 'content': 'B1: Mejni prehodi?akalna doba je na mejnih prehodih ObreÅ¾je, Dobovec in GruÅ¡kovje.Tovorni prometZaradi praznikov bo po Sloveniji v nedeljo, 1. 5. in v ponedeljek, 2. 5. med 8. in 22. uro, veljala omejitev prometa tovornih vozil, katerih najve?ja dovoljena masa presega 7,5 t.'}, {'role': 'assistant', 'content': 'Zaradi pokvarjenega vozila je na štajerski avtocesti v predoru Jasovnik zaprt vozni pas proti Ljubljani. Na mejnih prehodih Sečovlje, Petrina, Dragonja in Dobovec vozniki osebnih vozil na izstop iz države čakajo približno pol ure; na Obrežju, v Gruškovju ter Slovenski vasi pa 1 uro pri vstopu v državo. '}]}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/trainingdataset.csv\")\n",
    "traffic_examples = []\n",
    "for _, row in df.iterrows():\n",
    "    example = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": row[\"user_message\"]},\n",
    "            {\"role\": \"assistant\", \"content\": row[\"assistant_message\"]}\n",
    "        ]\n",
    "    }\n",
    "    traffic_examples.append(example)\n",
    "\n",
    "print(traffic_examples[:2])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a7b92c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not convert 'B1: Nesre?eCesta RoÅ¾na Dolina - AjÅ¡evica je pri AjÅ¡evici zaprta.Cesta Pesek - Oplotnica je v Oplotnici zaprta.OpozorilaNa avtocesti od SeÅ¾ane proti Mariboru, do Slovenskih Konjic, pelje izredni prevoz. Ob?asno je lahko promet oviran in upo?asnjen.Mejni prehodi?akalna doba je na mejnem prehodu ObreÅ¾je.Tovorni prometZaradi praznikov bo po Sloveniji v nedeljo, 1. 5. in v ponedeljek, 2. 5. med 8. in 22. uro, veljala omejitev prometa tovornih vozil, katerih najve?ja dovoljena masa presega 7,5 t.' with type str: tried to convert to double",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArrowInvalid\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\datasets\\arrow_writer.py:243\u001b[39m, in \u001b[36mTypedSequence.__arrow_array__\u001b[39m\u001b[34m(self, type)\u001b[39m\n\u001b[32m    242\u001b[39m     trying_cast_to_python_objects = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     out = \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[38;5;66;03m# use smaller integer precisions if possible\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\pyarrow\\array.pxi:372\u001b[39m, in \u001b[36mpyarrow.lib.array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\pyarrow\\array.pxi:42\u001b[39m, in \u001b[36mpyarrow.lib._sequence_to_array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\pyarrow\\error.pxi:155\u001b[39m, in \u001b[36mpyarrow.lib.pyarrow_internal_check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\pyarrow\\error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mArrowInvalid\u001b[39m: Could not convert 'B1: Nesre?eCesta RoÅ¾na Dolina - AjÅ¡evica je pri AjÅ¡evici zaprta.Cesta Pesek - Oplotnica je v Oplotnici zaprta.OpozorilaNa avtocesti od SeÅ¾ane proti Mariboru, do Slovenskih Konjic, pelje izredni prevoz. Ob?asno je lahko promet oviran in upo?asnjen.Mejni prehodi?akalna doba je na mejnem prehodu ObreÅ¾je.Tovorni prometZaradi praznikov bo po Sloveniji v nedeljo, 1. 5. in v ponedeljek, 2. 5. med 8. in 22. uro, veljala omejitev prometa tovornih vozil, katerih najve?ja dovoljena masa presega 7,5 t.' with type str: tried to convert to double",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mArrowInvalid\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m dataset = \u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraffic_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m dataset = dataset.train_test_split(test_size=\u001b[32m0.2\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(dataset[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:986\u001b[39m, in \u001b[36mDataset.from_list\u001b[39m\u001b[34m(cls, mapping, features, info, split)\u001b[39m\n\u001b[32m    984\u001b[39m \u001b[38;5;66;03m# for simplicity and consistency wrt OptimizedTypedSequence we do not use InMemoryTable.from_pylist here\u001b[39;00m\n\u001b[32m    985\u001b[39m mapping = {k: [r.get(k) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m mapping] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m mapping[\u001b[32m0\u001b[39m]} \u001b[38;5;28;01mif\u001b[39;00m mapping \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m--> \u001b[39m\u001b[32m986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:940\u001b[39m, in \u001b[36mDataset.from_dict\u001b[39m\u001b[34m(cls, mapping, features, info, split)\u001b[39m\n\u001b[32m    938\u001b[39m     arrow_typed_mapping[col] = data\n\u001b[32m    939\u001b[39m mapping = arrow_typed_mapping\n\u001b[32m--> \u001b[39m\u001b[32m940\u001b[39m pa_table = \u001b[43mInMemoryTable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    942\u001b[39m     info = DatasetInfo()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\datasets\\table.py:758\u001b[39m, in \u001b[36mInMemoryTable.from_pydict\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    742\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_pydict\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *args, **kwargs):\n\u001b[32m    744\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[33;03m    Construct a Table from Arrow arrays or columns.\u001b[39;00m\n\u001b[32m    746\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    756\u001b[39m \u001b[33;03m        `datasets.table.Table`\u001b[39;00m\n\u001b[32m    757\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\pyarrow\\table.pxi:1968\u001b[39m, in \u001b[36mpyarrow.lib._Tabular.from_pydict\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\pyarrow\\table.pxi:6337\u001b[39m, in \u001b[36mpyarrow.lib._from_pydict\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\pyarrow\\array.pxi:402\u001b[39m, in \u001b[36mpyarrow.lib.asarray\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\pyarrow\\array.pxi:252\u001b[39m, in \u001b[36mpyarrow.lib.array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\pyarrow\\array.pxi:114\u001b[39m, in \u001b[36mpyarrow.lib._handle_arrow_array_protocol\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\datasets\\arrow_writer.py:311\u001b[39m, in \u001b[36mTypedSequence.__arrow_array__\u001b[39m\u001b[34m(self, type)\u001b[39m\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m trying_cast_to_python_objects \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCould not convert\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     out = \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize_list_casting\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    313\u001b[39m         out = cast_array_to_feature(out, \u001b[38;5;28mtype\u001b[39m, allow_primitive_to_str=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_decimal_to_str=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\pyarrow\\array.pxi:372\u001b[39m, in \u001b[36mpyarrow.lib.array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\pyarrow\\array.pxi:42\u001b[39m, in \u001b[36mpyarrow.lib._sequence_to_array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\pyarrow\\error.pxi:155\u001b[39m, in \u001b[36mpyarrow.lib.pyarrow_internal_check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\turkf\\Pictures\\mag\\ONJ\\ONJyfans\\ul-fri-nlp-course-project-2024-2025-onjyfans\\venv\\Lib\\site-packages\\pyarrow\\error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mArrowInvalid\u001b[39m: Could not convert 'B1: Nesre?eCesta RoÅ¾na Dolina - AjÅ¡evica je pri AjÅ¡evici zaprta.Cesta Pesek - Oplotnica je v Oplotnici zaprta.OpozorilaNa avtocesti od SeÅ¾ane proti Mariboru, do Slovenskih Konjic, pelje izredni prevoz. Ob?asno je lahko promet oviran in upo?asnjen.Mejni prehodi?akalna doba je na mejnem prehodu ObreÅ¾je.Tovorni prometZaradi praznikov bo po Sloveniji v nedeljo, 1. 5. in v ponedeljek, 2. 5. med 8. in 22. uro, veljala omejitev prometa tovornih vozil, katerih najve?ja dovoljena masa presega 7,5 t.' with type str: tried to convert to double"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_list(traffic_examples)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "print(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779971b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's check what resources we have available\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "model.to(\"cuda\")\n",
    "def check_resources():\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    \n",
    "    import psutil\n",
    "    print(f\"CPU cores: {psutil.cpu_count(logical=False)} physical, {psutil.cpu_count()} logical\")\n",
    "    print(f\"RAM: {psutil.virtual_memory().total / 1024**3:.2f} GB total\")\n",
    "    print(f\"Available RAM: {psutil.virtual_memory().available / 1024**3:.2f} GB\")\n",
    "\n",
    "# Check resources before starting\n",
    "check_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "def train_model(model_id, dataset):\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "    model.to(\"cuda\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    \n",
    "    def preprocess_function(examples):\n",
    "        texts = []\n",
    "        for conversation in examples[\"messages\"]:\n",
    "            formatted_text = \"\"\n",
    "            for message in conversation:\n",
    "                if message[\"role\"] == \"user\":\n",
    "                    formatted_text += f\"Uporabnik: {message['content']}\\n\"\n",
    "                else:\n",
    "                    formatted_text += f\"Asistent: {message['content']}\\n\"\n",
    "            texts.append(formatted_text)\n",
    "        \n",
    "        tokenized = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=512)\n",
    "        return tokenized\n",
    "    \n",
    "    tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=6,\n",
    "        per_device_eval_batch_size=6,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=10,\n",
    "    )\n",
    "    \n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=False  \n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"test\"],\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    model.save_pretrained(\"./fine-tuned-traffic-model\")\n",
    "    tokenizer.save_pretrained(\"./fine-tuned-traffic-model\")\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "#model_id = \"cjvt/OPT_GaMS-1B-Chat\"\n",
    "model_id = \"cjvt/OPT_GaMS-1B-Chat\"\n",
    "model, tokenizer = train_model(model_id, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f20c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71260475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "# First, clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "# Example traffic data (small sample to test with)\n",
    "traffic_examples = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Generiraj poročilo o prometu za avtocesto A1 med Ljubljano in Mariborom.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Na avtocesti A1 med Ljubljano in Mariborom trenutno ni posebnosti. Promet poteka tekoče v obeh smereh.\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Stanje na cestah v Ljubljani?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"V Ljubljani trenutno ni večjih zastojev. Na Celovški cesti so dela, ki upočasnjujejo promet.\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create a smaller dataset for initial testing\n",
    "dataset = Dataset.from_list(traffic_examples)\n",
    "dataset = dataset.train_test_split(test_size=0.5)  # 50/50 split for this tiny example\n",
    "\n",
    "def train_model(model_id, dataset, device_map=\"auto\"):\n",
    "    try:\n",
    "        # More careful model loading with resource management\n",
    "        print(f\"Loading model from {model_id}...\")\n",
    "        print(f\"Available GPU: {torch.cuda.is_available()}, Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "        \n",
    "        # Try to load with lower precision to save memory\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            device_map=device_map,       # Distribute across available GPUs or use CPU\n",
    "            torch_dtype=torch.float16,   # Use half precision to save memory\n",
    "            low_cpu_mem_usage=True       # More memory-efficient loading\n",
    "        )\n",
    "        \n",
    "        print(\"Model loaded successfully\")\n",
    "        \n",
    "        # Load tokenizer (this is usually much lighter)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        print(\"Tokenizer loaded successfully\")\n",
    "        \n",
    "        def preprocess_function(examples):\n",
    "            texts = []\n",
    "            for conversation in examples[\"messages\"]:\n",
    "                formatted_text = \"\"\n",
    "                for message in conversation:\n",
    "                    if message[\"role\"] == \"user\":\n",
    "                        formatted_text += f\"Uporabnik: {message['content']}\\n\"\n",
    "                    else:\n",
    "                        formatted_text += f\"Asistent: {message['content']}\\n\"\n",
    "                texts.append(formatted_text)\n",
    "            \n",
    "            tokenized = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=512)\n",
    "            return tokenized\n",
    "        \n",
    "        # Process the dataset\n",
    "        print(\"Preprocessing dataset...\")\n",
    "        tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "        print(\"Dataset preprocessed successfully\")\n",
    "        \n",
    "        # Training arguments with lower memory footprint\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"./results\",\n",
    "            num_train_epochs=1,             # Start with fewer epochs for testing\n",
    "            per_device_train_batch_size=1,  # Smaller batch size\n",
    "            per_device_eval_batch_size=1,   # Smaller batch size\n",
    "            warmup_steps=10,                # Fewer warmup steps\n",
    "            weight_decay=0.01,\n",
    "            logging_dir=\"./logs\",\n",
    "            logging_steps=1,\n",
    "            # Memory optimization settings\n",
    "            gradient_accumulation_steps=4,  # Accumulate gradients to simulate larger batch\n",
    "            fp16=torch.cuda.is_available(), # Use FP16 if GPU available\n",
    "            dataloader_num_workers=0,       # Don't use multiple workers\n",
    "        )\n",
    "        \n",
    "        # Create data collator\n",
    "        data_collator = DataCollatorForLanguageModeling(\n",
    "            tokenizer=tokenizer,\n",
    "            mlm=False\n",
    "        )\n",
    "        \n",
    "        # Create trainer\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_dataset[\"train\"],\n",
    "            eval_dataset=tokenized_dataset[\"test\"],\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "        \n",
    "        print(\"Starting training...\")\n",
    "        trainer.train()\n",
    "        print(\"Training completed\")\n",
    "        \n",
    "        # Save model\n",
    "        model.save_pretrained(\"./fine-tuned-traffic-model\")\n",
    "        tokenizer.save_pretrained(\"./fine-tuned-traffic-model\")\n",
    "        \n",
    "        return model, tokenizer\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during model loading or training: {e}\")\n",
    "        \n",
    "        # If the error is related to CUDA out of memory, try CPU\n",
    "        if \"CUDA out of memory\" in str(e) and device_map == \"auto\":\n",
    "            print(\"GPU memory error detected. Trying to load on CPU instead...\")\n",
    "            return train_model(model_id, dataset, device_map=\"cpu\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "# Try loading with smaller model first to test\n",
    "try:\n",
    "    print(\"First trying a smaller model to verify environment...\")\n",
    "    small_model_id = \"cjvt/OPT_SloT-300M-Chat\"  # Much smaller model\n",
    "    test_model = AutoModelForCausalLM.from_pretrained(small_model_id, torch_dtype=torch.float16)\n",
    "    print(\"Small model loaded successfully, environment seems functional\")\n",
    "    del test_model  # Free the memory\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "except Exception as e:\n",
    "    print(f\"Error loading test model: {e}\")\n",
    "\n",
    "# Now try the actual model\n",
    "try:\n",
    "    model_id = \"cjvt/OPT_GaMS-1B-Chat\"\n",
    "    model, tokenizer = train_model(model_id, dataset)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to train model: {e}\")\n",
    "    print(\"Attempting to load model without training...\")\n",
    "    try:\n",
    "        # Just load the model to check if that's possible\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id, \n",
    "            device_map=\"cpu\",\n",
    "            torch_dtype=torch.float16\n",
    "        )\n",
    "        print(\"Model loaded successfully without training\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Model loading also failed: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb46b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "def generate_traffic_report(prompt, model_path=\"./fine-tuned-traffic-model\"):\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    \n",
    "    generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")\n",
    "    \n",
    "    formatted_input = f\"Uporabnik: {prompt}\\nAsistent:\"\n",
    "    \n",
    "    response = generator(formatted_input, max_length=200, do_sample=True, temperature=0.7, truncation=True)\n",
    "    \n",
    "    assistant_response = response[0][\"generated_text\"].split(\"Asistent:\")[1].strip()\n",
    "    \n",
    "    return assistant_response\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Poročaj o stanju na primorski avtocesti med Vrhniko in Koprom. Dela na cesti pri Postojni.\"\n",
    "report = generate_traffic_report(prompt)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38204f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def evaluate_model(model_path, test_examples):\n",
    "    # Create evaluation dataset\n",
    "    eval_dataset = Dataset.from_list(test_examples)\n",
    "    \n",
    "    # Load model and tokenizer\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    \n",
    "    # Create generator\n",
    "    generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")\n",
    "    \n",
    "    # Evaluate on each example\n",
    "    results = []\n",
    "    for example in test_examples:\n",
    "        user_input = example[\"messages\"][0][\"content\"]\n",
    "        expected_output = example[\"messages\"][1][\"content\"]\n",
    "        \n",
    "        # Generate response\n",
    "        formatted_input = f\"Uporabnik: {user_input}\\nAsistent:\"\n",
    "        response = generator(formatted_input, max_length=200)\n",
    "        generated = response[0][\"generated_text\"].split(\"Asistent:\")[1].strip()\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"input\": user_input,\n",
    "            \"expected\": expected_output,\n",
    "            \"generated\": generated\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example evaluation\n",
    "test_examples = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Kakšno je stanje na gorenjski avtocesti proti Jesenicam?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Na gorenjski avtocesti proti Jesenicam trenutno ni posebnosti ali zastojev. Promet poteka tekoče na celotnem odseku.\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "evaluation_results = evaluate_model(\"./fine-tuned-traffic-model\", test_examples)\n",
    "print(evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e822eb",
   "metadata": {},
   "source": [
    "Evaluation will then follow next procedures.: \n",
    "\n",
    "1. Consistent Examples in Training Data\n",
    "The most straightforward approach is providing numerous consistent examples:\n",
    "\n",
    "Include many examples with correct road naming formats\n",
    "Ensure consistency across all training examples\n",
    "Cover all variations of road types (highways, regional roads, streets)\n",
    "\n",
    "For example, always using formats like:\n",
    "\n",
    "\"avtocesta A1\" (not just \"A1\")\n",
    "\"regionalna cesta R2-409\" (with full designation)\n",
    "\"Celovška cesta\" (with proper capitalization)\n",
    "\n",
    "2. Instruction-Based Fine-tuning\n",
    "You can explicitly teach the model road naming rules:\n",
    "pythonroad_naming_examples = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Kako pravilno poimenovati avtocesto A1?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Avtocesta A1 se pravilno imenuje 'avtocesta A1' ali 'avtocesta A1 Šentilj-Srmin'. Pri prvem omenjanju v poročilu uporabite polno ime, kasneje lahko uporabite krajšo obliko 'A1'.\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Navedi pravila za poimenovanje cest v prometnih poročilih.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Pri poimenovanju cest v prometnih poročilih upoštevajte naslednja pravila:\\n1. Avtoceste: 'avtocesta A1', ne samo 'A1'\\n2. Hitre ceste: 'hitra cesta H4', ne samo 'H4'\\n3. Regionalne ceste: 'regionalna cesta R2-409'\\n4. Mestne ceste: uporabite polno ime, npr. 'Celovška cesta', ne 'Celovška'\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "Add these instructional examples to your training data to explicitly teach rules.\n",
    "3. Data Augmentation with Rule Enforcement\n",
    "Create augmented examples that specifically focus on proper naming:\n",
    "python# Original example\n",
    "original = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Poročaj o stanju na A1.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Na avtocesti A1 med Ljubljano in Mariborom trenutno ni zastojev.\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Add variations with correct naming to reinforce the rule\n",
    "variations = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Poročaj o stanju na A1 proti Mariboru.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Na avtocesti A1 v smeri proti Mariboru trenutno ni posebnosti.\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Kako je na A1?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Na avtocesti A1 Šentilj-Srmin je promet tekoč v obeh smereh.\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "4. Post-Processing Rules\n",
    "For critical naming conventions, you can implement post-processing:\n",
    "pythondef enforce_road_naming(generated_text):\n",
    "    # Dictionary of road type patterns and their correct forms\n",
    "    road_patterns = {\n",
    "        r'\\b(A\\d+)\\b(?! avtocest)': r'avtocesta \\1',  # A1 → avtocesta A1\n",
    "        r'\\b(H\\d+)\\b(?! hitr)': r'hitra cesta \\1',    # H4 → hitra cesta H4\n",
    "        # Add more patterns as needed\n",
    "    }\n",
    "    \n",
    "    # Apply all patterns\n",
    "    result = generated_text\n",
    "    for pattern, replacement in road_patterns.items():\n",
    "        result = re.sub(pattern, replacement, result)\n",
    "        \n",
    "    return result\n",
    "\n",
    "# Use this after generation\n",
    "response = generate_traffic_report(prompt)\n",
    "corrected_response = enforce_road_naming(response)\n",
    "5. Evaluation and Filtering\n",
    "Create a specific evaluation metric for road naming compliance:\n",
    "pythondef evaluate_road_naming(generated_text):\n",
    "    # Define patterns for improper road naming\n",
    "    improper_patterns = [\n",
    "        r'\\b(A\\d+)\\b(?! avtocest)',  # A1 without \"avtocesta\"\n",
    "        r'\\b(H\\d+)\\b(?! hitr)',      # H4 without \"hitra cesta\"\n",
    "        # Add more patterns\n",
    "    ]\n",
    "    \n",
    "    # Count violations\n",
    "    violations = 0\n",
    "    for pattern in improper_patterns:\n",
    "        violations += len(re.findall(pattern, generated_text))\n",
    "        \n",
    "    return {\n",
    "        \"violations\": violations,\n",
    "        \"compliant\": violations == 0\n",
    "    }\n",
    "Practical Implementation Approach\n",
    "Here's how I recommend implementing these strategies:\n",
    "\n",
    "Start with data quality: Ensure all your training examples use correct road naming\n",
    "Add instruction examples: Include specific examples teaching the naming rules\n",
    "Evaluate during development: Create a custom metric to track naming compliance\n",
    "Implement post-processing: As a safety net for critical applications\n",
    "\n",
    "By combining these approaches, you'll significantly improve your model's adherence to specific road naming conventions while still maintaining natural-sounding Slovenian text.\n",
    "Would you like me to elaborate on any of these strategies or provide more specific examples for Slovenian road naming conventions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c21e25",
   "metadata": {},
   "source": [
    "Zero shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f0e638",
   "metadata": {},
   "source": [
    "few shot prompting with all the rules exmplained?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
